{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsNGFEavkLpZ"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "#   ML PIPELINE FOR WINE QUALITY (COMBINED FULL + TUNED MODELS)\n",
        "#   WITH FULL EDA SECTION INSERTED\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, KFold, cross_val_score,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    ExtraTreesClassifier,\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqUdIV2HkL5q",
        "outputId": "c29b5253-466b-40e4-e0d7-cd2fab10c0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- 1. DATA LOADING & EXPLORATION ---\n",
            "Error: WineQT.csv not found.\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mError: WineQT.csv not found.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m     exit()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdata\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.head())\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMissing Values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, data.isnull().sum())\n",
            "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 1. DATA LOADING\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- 1. DATA LOADING & EXPLORATION ---\")\n",
        "\n",
        "try:\n",
        "    data = pd.read_csv(\"/content/WineQT.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: WineQT.csv not found.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Shape: {data.shape}\")\n",
        "print(data.head())\n",
        "print(\"Missing Values:\\n\", data.isnull().sum())\n",
        "\n",
        "df = data.copy()  # For EDA usage consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKr5zFpkMBA",
        "outputId": "f5142ffb-b4fb-448f-801c-0556d25dc91b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 1B. FULL EDA SECTION (YOUR NEWLY ADDED CODE)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- 1B. EXPLORATORY DATA ANALYSIS (EDA) ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k0nsz2lVkL9Y",
        "outputId": "010648b6-d0d9-4d65-f7b8-4da4ab3fea76"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =============================\n",
        "# HISTOGRAMS WITH KDE\n",
        "# =============================\n",
        "num_features = df.columns.drop(\"quality\")\n",
        "\n",
        "plt.figure(figsize=(15, 25))\n",
        "for i, feature in enumerate(num_features):\n",
        "    plt.subplot(len(num_features)//3 + 1, 3, i+1)\n",
        "    sns.histplot(df[feature], kde=True)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Density')\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nHistograms with KDE generated for all features.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6ATYGq6LkMEi",
        "outputId": "04ff47cc-55db-4a7e-be7a-7e8a57d82514"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =============================\n",
        "# BOXPLOTS FOR OUTLIERS\n",
        "# =============================\n",
        "plt.figure(figsize=(15, 25))\n",
        "for i, feature in enumerate(num_features):\n",
        "    plt.subplot(len(num_features)//3 + 1, 3, i+1)\n",
        "    sns.boxplot(y=df[feature])\n",
        "    plt.title(f'Box plot of {feature}')\n",
        "    plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Boxplots for all numerical features generated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "id": "xpJLyNJEkMHw",
        "outputId": "25620037-7e4c-4b18-c2b7-67ff092540b5"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# CORRELATION MATRIX\n",
        "# =============================\n",
        "correlation_matrix_X = df[num_features].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix_X, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Features')\n",
        "plt.show()\n",
        "\n",
        "# Combine X + y for target correlation\n",
        "correlations_with_target = df.corr()['quality'].drop('quality')\n",
        "\n",
        "print(\"\\nCorrelations with target variable:\")\n",
        "print(correlations_with_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "hMLXZih2kMLA",
        "outputId": "a7d50633-e919-4512-dd5a-8588031fc7cf"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# QUALITY DISTRIBUTION (BAR + PIE)\n",
        "# =============================\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Bar chart\n",
        "plt.subplot(1, 2, 1)\n",
        "quality_counts = df['quality'].value_counts().sort_index()\n",
        "plt.bar(quality_counts.index, quality_counts.values, edgecolor='black')\n",
        "plt.title('Quality Rating Distribution')\n",
        "plt.xlabel('Quality')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Pie chart\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pie(\n",
        "    quality_counts,\n",
        "    autopct=lambda p: f'{p:.1f}%' if p > 1 else '',\n",
        "    startangle=90,\n",
        "    pctdistance=1.2,\n",
        "    labeldistance=1.3,\n",
        "    textprops={'fontsize': 12},\n",
        "    wedgeprops={'edgecolor': 'white', 'linewidth': 1}\n",
        ")\n",
        "plt.legend(\n",
        "    quality_counts.index,\n",
        "    title=\"Quality Rating\",\n",
        "    loc=\"center left\",\n",
        "    bbox_to_anchor=(1, 0.5)\n",
        ")\n",
        "plt.title('Proportion of Quality Ratings')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "JDL6JojCkMOH",
        "outputId": "59ff6b9c-66b2-4480-9549-cb0a5d639190"
      },
      "outputs": [],
      "source": [
        "\n",
        "# =============================\n",
        "# BOX PLOTS OF FEATURES VS TARGET\n",
        "# =============================\n",
        "key_features = df.columns.drop(\"quality\")\n",
        "\n",
        "plt.figure(figsize=(18, 12))\n",
        "p = len(key_features)\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    plt.subplot(round(p**0.5) + 1, round(p**0.5) + 1, i + 1)\n",
        "    sns.boxplot(x=df[\"quality\"], y=df[feature])\n",
        "    plt.title(f'{feature} vs Quality')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Boxplots showing relationship between features and quality generated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LeMC7bIkryP",
        "outputId": "658a40e8-259d-4909-cceb-4f99460042cc"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 2. PREPROCESSING (QUALITY BINARIZATION)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- 2. PREPROCESSING ---\")\n",
        "\n",
        "# Convert quality ‚Üí binary classes\n",
        "bins = (2, 6.5, 8)\n",
        "labels = ['Bad', 'Good']\n",
        "data['quality'] = pd.cut(data['quality'], bins=bins, labels=labels)\n",
        "\n",
        "lc = LabelEncoder()\n",
        "data['quality'] = lc.fit_transform(data['quality'])\n",
        "\n",
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "OuvhCJYBkr6m",
        "outputId": "297c905e-4f0e-487d-9a43-9e4d91f12d8e"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 2C. FEATURE IMPORTANCE (EXTRATREES)\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "extra = ExtraTreesClassifier(random_state=42)\n",
        "extra_feat = extra.fit(X, y)\n",
        "ex_data = pd.Series(extra_feat.feature_importances_, index=X.columns)\n",
        "\n",
        "print(\"\\nTop 5 Feature Importances:\")\n",
        "print(ex_data.nlargest(5))\n",
        "\n",
        "# Feature importance plot\n",
        "plt.figure(figsize=(10,5))\n",
        "ex_data.sort_values().plot(kind='bar')\n",
        "plt.title(\"Feature Importances (ExtraTreesClassifier)\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPcvIF2xksCJ"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 2D. TRAIN‚ÄìTEST SPLIT & STANDARDIZATION\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0vN-QhvksGP",
        "outputId": "77a33ae9-84f5-4ed1-edc0-6b38202b7f9e"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 3. BASELINE MODELS\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- 3. BASELINE MODELS ---\")\n",
        "\n",
        "models = [\n",
        "    (\"Logistic Regression\", LogisticRegression(random_state=42, solver='liblinear')),\n",
        "    (\"KNN\", KNeighborsClassifier()),\n",
        "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
        "    (\"SVC\", SVC(random_state=42)),\n",
        "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
        "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
        "]\n",
        "\n",
        "baseline_results = []\n",
        "\n",
        "for name, model in models:\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    baseline_results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'F1-Good': report['1']['f1-score']\n",
        "    })\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "baseline_df = pd.DataFrame(baseline_results).sort_values(by=\"F1-Good\", ascending=False)\n",
        "print(\"\\nBASELINE SUMMARY:\\n\", baseline_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJMP71ZGksJD",
        "outputId": "7c092ef4-e7e9-4c92-c7ea-7717118cf06d"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------------------\n",
        "# 4. HYPERPARAMETER TUNING\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- 4. HYPERPARAMETER TUNING (RandomizedSearchCV) ---\")\n",
        "\n",
        "TUNING_SCORING = \"f1\"\n",
        "N_ITER_SEARCH = 15\n",
        "CV_FOLDS = 5\n",
        "\n",
        "models_to_tune = [\n",
        "\n",
        "    (\"Logistic Regression\", LogisticRegression(random_state=42, solver=\"liblinear\"), {\n",
        "        \"C\": np.logspace(-3, 2, 10),\n",
        "        \"penalty\": [\"l1\", \"l2\"]\n",
        "    }),\n",
        "\n",
        "    (\"KNN\", KNeighborsClassifier(), {\n",
        "        \"n_neighbors\": np.arange(1, 25),\n",
        "        \"weights\": [\"uniform\", \"distance\"]\n",
        "    }),\n",
        "\n",
        "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42), {\n",
        "        \"max_depth\": np.arange(2, 15),\n",
        "        \"min_samples_split\": np.arange(2, 10),\n",
        "        \"min_samples_leaf\": np.arange(1, 5)\n",
        "    }),\n",
        "\n",
        "    (\"SVC\", SVC(random_state=42), {\n",
        "        \"C\": np.logspace(-1, 2, 10),\n",
        "        \"gamma\": np.logspace(-3, 0, 10)\n",
        "    }),\n",
        "\n",
        "    (\"Random Forest\", RandomForestClassifier(random_state=42), {\n",
        "        \"n_estimators\": [200, 300, 500],\n",
        "        \"max_depth\": [5, 10, 20, None],\n",
        "        \"min_samples_leaf\": [1, 2, 4]\n",
        "    }),\n",
        "\n",
        "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42), {\n",
        "        \"n_estimators\": [200, 300, 500],\n",
        "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "        \"max_depth\": [3, 5, 8]\n",
        "    }),\n",
        "]\n",
        "\n",
        "tuned_results = []\n",
        "tuned_models = []\n",
        "\n",
        "for name, model, grid in models_to_tune:\n",
        "\n",
        "    print(f\"\\nüîç Tuning {name}...\")\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "        model,\n",
        "        grid,\n",
        "        n_iter=N_ITER_SEARCH,\n",
        "        cv=CV_FOLDS,\n",
        "        scoring=TUNING_SCORING,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    search.fit(x_train, y_train)\n",
        "    best = search.best_estimator_\n",
        "\n",
        "    tuned_models.append((name, best))\n",
        "    print(f\"Best params: {search.best_params_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jUmr2xEHk-II",
        "outputId": "266c5f0a-5b3d-4022-b7aa-c0f996bba1e5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---------------------------------------------------------------\n",
        "# 5. FINAL EVALUATION OF TUNED MODELS\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- 5. FINAL RESULTS (TUNED MODELS) ---\")\n",
        "\n",
        "for name, model in tuned_models:\n",
        "\n",
        "    print(f\"\\nEvaluating Tuned {name}...\")\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    tuned_results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"F1-Good\": report[\"1\"][\"f1-score\"]\n",
        "    })\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "tuned_df = pd.DataFrame(tuned_results).sort_values(by=\"F1-Good\", ascending=False)\n",
        "print(\"\\nTUNED MODEL SUMMARY:\\n\", tuned_df)\n",
        "\n",
        "# Plot Tuned Model F1 Scores\n",
        "plt.figure(figsize=(9, 5))\n",
        "sns.barplot(x=\"F1-Good\", y=\"Model\", data=tuned_df, palette=\"viridis\")\n",
        "plt.title(\"F1 Score (Good Class) - Tuned Models\")\n",
        "plt.show()\n",
        "\n",
        "best_model = tuned_df.iloc[0]\n",
        "print(f\"\\nüèÜ Best Model: {best_model['Model']}  (F1 = {best_model['F1-Good']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V27rv512k-RP"
      },
      "outputs": [],
      "source": [
        "# import joblib\n",
        "# model_filename = \"best_wine_quality_model.pkl\"\n",
        "# joblib.dump(tuned_models[0][1], model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60GbIkHDk-UV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AMF_o6Lk-Xi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
